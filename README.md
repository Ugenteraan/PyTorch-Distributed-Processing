# PyTorch-Distributed-Processing
Distributed data parallel training in Pytorch using MNIST model as example.

Source : https://github.com/yangkky/distributed_tutorial